\documentclass{article}

\usepackage[final]{nips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
\usepackage{mathtools}

\usepackage{subfiles}

\usepackage{graphicx}


\title{CECS 551 Midterm Report}
\author{%
  Jared R.~Coleman\\
  Computer Engineering and Computer Science\\
  California State University, Long Beach\\
  Long Beach, CA 90802 \\
  \texttt{jared.coleman@student.csulb.edu} \\
  \And 
  Taina G.D.~Coleman\\
  Computer Engineering and Computer Science\\
  California State University, Long Beach\\
  Long Beach, CA 90802 \\
  \texttt{taina.coleman@student.csulb.edu} \\
  \And 
  Ian M. ~Schenck\\
  Computer Engineering and Computer Science\\
  California State University, Long Beach\\
  Long Beach, CA 90802 \\
  \texttt{ian.schenck@student.csulb.edu} \\
}

\begin{document}
\stepcounter{equation}
\setcounter{equation}{0}

\maketitle

\begin{abstract}
  
\end{abstract}

\subfile{introduction}
\subfile{gcn}
\subfile{experiments}
\subfile{conclusion}

\section{Conclusion \& Future Work}
The GCN model is shown to be more effective than other proposed methods of deep learning on graph data, but it is not without its flaws. The memory requirement is $\mathcal{O}(\mathcal{E})$, growing linearly with the dataset, so very large datasets can cause problems. Also, this model does not function well with more than a few layers. One paper that improves upon the GCN focuses on further understanding GCN while proposing a combined co-training and self-training method to improve classification accuracy without requiring additional labels in the training set~\cite{Li2018}. Another paper proposes adaptive layer-wise sampling to accelerate training and reduce memory requirements~\cite{Huang2018}. A third paper we want to research develops a new method of applying convolutional operations on graphs called learnable graph convolutional layers, which allows for deeper networks and yields higher classification accuracy with less memory usage than the GCN~\cite{Gao2018}. For the next part of the semester we plan on implementing a Graph Convolutional Network, hopefully utilizing some of the improvements developed above.
  
\bibliographystyle{plain}
\bibliography{references}

\end{document}

